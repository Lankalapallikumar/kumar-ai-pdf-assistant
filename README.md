---
title: Kumar AI PDF Chat
emoji: ğŸ¤–
colorFrom: purple
colorTo: blue
sdk: docker
app_file: app.py
pinned: false
---

# ğŸ¤– Kumar AI Study Assistant

> Conversational AI that lets you chat with any PDF using Retrieval-Augmented Generation (RAG) + LLaMA 3.1.

![Python](https://img.shields.io/badge/Python-3.11-blue)
![LangChain](https://img.shields.io/badge/LangChain-RAG-green)
![Groq](https://img.shields.io/badge/Groq-LLaMA3.1-orange)
![Streamlit](https://img.shields.io/badge/Streamlit-WebApp-red)
![License](https://img.shields.io/badge/License-MIT-lightgrey)

---

## ğŸš€ Overview

Kumar AI Study Assistant allows users to upload any PDF (textbooks, notes, research papers) and interact with it through a conversational AI interface.

Instead of manually searching documents, the system retrieves the most relevant sections using vector search and generates accurate, context-aware answers using LLaMA 3.1.

This project demonstrates a complete **Conversational RAG pipeline**.

---

## ğŸ§  How It Works
PDF Upload
â†“
Text Splitting (Chunking)
â†“
Embedding Generation
â†“
FAISS Vector Store
â†“
User Question
â†“
Top-K Semantic Retrieval
â†“
LLaMA 3.1 (via Groq)
â†“
Answer + Source References

---

## âœ¨ Key Features

- ğŸ“„ Upload any PDF
- ğŸ’¬ Continuous conversational chat
- ğŸ” Semantic Top-K retrieval
- ğŸ“š Source citation preview
- âš¡ Fast inference using Groq
- ğŸ¨ Modern Streamlit UI
- ğŸ³ Docker-ready
- â˜ï¸ Hugging Face Spaces compatible
- ğŸ§  Chat memory support

---

## âš™ï¸ Configuration

All major settings are configurable in `config.py`:

| Parameter | Description |
|----------|-------------|
| `llm_model` | LLaMA model version |
| `llm_temperature` | Controls creativity |
| `chunk_size` | PDF text chunk size |
| `chunk_overlap` | Overlap between chunks |
| `retriever_k` | Number of retrieved chunks |
| `max_file_size_mb` | Upload size limit |

---

## ğŸ›  Tech Stack

| Tool | Purpose |
|------|---------|
| LangChain | RAG orchestration |
| FAISS | Vector similarity search |
| HuggingFace Embeddings | Text embeddings |
| Groq API | LLaMA 3.1 inference |
| Streamlit | Web UI |
| Docker | Containerized deployment |

---

## â–¶ï¸ Run Locally (Docker)

```bash
docker-compose up --build
