# config.py
from dataclasses import dataclass

@dataclass
class AppConfig:
    # â”€â”€ App Info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    app_title: str = "ðŸ¤– Kumar AI Study Assistant"
    app_icon: str = "ðŸ¤–"
    app_description: str = "Chat with any PDF using Conversational RAG + LLaMA 3 â€” built for smart learning."
    layout: str = "wide"

    # â”€â”€ Model Settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    llm_model: str = "llama-3.1-8b-instant"
    llm_temperature: float = 0.25
    embedding_model: str = "sentence-transformers/all-MiniLM-L6-v2"

    # â”€â”€ RAG Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    chunk_size: int = 800
    chunk_overlap: int = 100
    retriever_k: int = 2   # <-- TOP 2 chunks only

    # â”€â”€ UI Limits â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    max_file_size_mb: int = 10

    # â”€â”€ Author Info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    author_name: str = "Lankalapalli Kumar"
    github_url: str = "https://github.com/Lankalapallikumar"
    linkedin_url: str = "https://www.linkedin.com/in/kumar-lankalapalli-datascience-ml"

config = AppConfig()